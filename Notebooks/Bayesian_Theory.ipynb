{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l1345"
    ]
   },
   "source": [
    "# Probability and Bayesian Theory\n",
    "\n",
    "## Additive and Multiplicative Rules of Probability\n",
    "\n",
    "Consider $A$,$B$ are two events, and $P$ denotes the probability of occurence of an event. \n",
    "\n",
    "Lets define the events as:\n",
    "* $A$ - Rolling a 4 on a fair die\n",
    "* $B$ - Rolling a 3 on a fair die\n",
    "\n",
    "With these event definitions we can observe that occurrence of $A$ prevents the occurrence of $B$ (or any other event in the sample space). Hence such events are called Mutually Exclusive Events.\n",
    "\n",
    "### Sample Space of an Event\n",
    "\n",
    "Sample space is the set of all possible favorable outcomes of an event. In the above example, each of the events $A$ and $B$ have one outcome in their sample space.\n",
    "$A_0,A_1,A_2...A_n$ could be possible outcomes in the sample space of $A$ and similarly, $B_0,B_1,B_2...B_n$ be possible outcomes in the sample space of $B$.\n",
    "\n",
    "If I re-define $A$ and $B$ from above example as:\n",
    "* $A$ - Rolling an even number on a fair die\n",
    "* $B$ - Rolling an odd number on a fair die\n",
    "\n",
    "now the sample spaces of $A$ and $B$ each have 3 favorable outcomes each.\n",
    "\n",
    "### Additive Rule\n",
    "\n",
    "The additive rule of probability says that, for two events $A$ and $B$, the probability of occurrence of either event A or event B can be defined as, the total of the probability of occurrence of event $A$ and the probability of occurrence of event $B$ minus the probability of occurrence of both $A$ and $B$.\n",
    "\n",
    "$P(A\\cup B)=P(A)+P(B)-P(A\\cap B)$\n",
    "\n",
    "If $A$ and $B$ are mutually exclusive events, i.e., there is no overlap in sample spaces of event $A$ and event $B$, then $P(A\\cap B)=0$. So,\n",
    "\n",
    "$P(A\\cup B)=P(A)+P(B)$\n",
    "\n",
    "Considering a set of mutually exclusive events, $A,B,C,D...$ so on, we can write additive rule as:\n",
    "\n",
    "$P(A\\cup B \\cup C \\cup D...)=P(A)+P(B)+P(C)+P(D)...$\n",
    "\n",
    "### Multiplicative Rule\n",
    "\n",
    "Consider the example of drawing a ball from a bucket consisting of many different colored balls. For simplicity, consider that there are only two different colored balls - 6 Green balls and 4 Red balls, 10 balls in total. Now draws can be made in two different ways:\n",
    "\n",
    "* with replacement - The ball drawn in every single draw is kept back into the bucket, keeping the total number of balls and mixture of colored balls constant, from draw to draw.\n",
    "\n",
    "* without replacement - A ball drawn in a single draw is retained and not replaced or substituted in any way in the bucket. This changes total number of balls and mixture of balls with each draw. Note that with no replacement or substitution, the total number of single ball draws that can be made in the bucket would be equal to the total number of balls in the bucket.\n",
    "\n",
    "<img src=\"../images/bib.png\", style=\"height:60vh;\">\n",
    "\n",
    "When balls are drawn without replacements, each draw affects the probabilities/outcomes of subsequent draws and say, the outcome of the second draw will be dependent upon the outcome of the first draw. In the same scenario, if balls are drawn with replacement, that is, every ball drawn is kept back into the bucket or is replaced with an identical ball, then every draw is independent of another/subsequent draws.\n",
    "\n",
    "So, when the probability of occurrence of event A does not, in any way, affect the probability of occurrence of event B and vice versa, then A and B are said to be independent events (events whose probability of occurrence is independent of each other).\n",
    "\n",
    "Examples are \n",
    "\n",
    "* Tossing of two coins : Occurrence of heads in one coin is independent of occurrence of heads/tails in the second coin.\n",
    "* Rolling of two dice  : The number on one die does not in any way affect the number on rolling the second die.\n",
    "\n",
    "\n",
    "<img src=\"../images/Independent_events.png\", style=\"height:60vh;\">\n",
    "\n",
    "According to the <b>Multiplication Rule</b>, if $A$ and $B$ are two independent events then,\n",
    "\n",
    "$P(A \\cap B) = P(A) * P(B)$\n",
    "\n",
    "Conditional probability of occurence of event A given event B has occurred is given by,\n",
    "\n",
    "$P(A|B) = \\large \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "But since $A$ and $B$ are independent events,\n",
    "\n",
    "$P(A|B) = \\large \\frac{P(A) * P(B)}{P(B)}$\n",
    "\n",
    "$P(A|B) = P(A)$\n",
    "\n",
    "Now we can see that conditional probability of $A$ given $B$ is equal to $A$ itself, which goes to show that occurrence or non-occurrence of $B$ does not affect the probability of occurrence of $A$ in any way.\n",
    "\n",
    "This is called <b>\"Conditional Independence\"</b> of event $A$ over event $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l1345"
    ]
   },
   "outputs": [],
   "source": [
    "# Click the run button to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l1345"
    ]
   },
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s1",
     "content",
     "l1"
    ]
   },
   "source": [
    "\n",
    "## Binary Communication System\n",
    "\n",
    "\n",
    "Consider a binary communication system where the input is either a 0 or a 1 with probability p. The receiver has an error with probability $\\epsilon$ which would mean that the received data gets flipped [Alberto-1]. This can be illustrated as shown in the figure below:\n",
    "<img src=\"../images/bc_system1.png\", style=\"width: 700px;\">\n",
    "[Alberto-1]Probability, Statistics and Random Processes for Electrical Engineering, Chap 2, Alberto Leon Garcia.\n",
    "\n",
    "What we computed above is called as the theorem of total probability. Let $B_1 , B_2 , ... , B_n$ be mutually exclusive events whose union equals the sample space S[Alberto]. We refer to these sets as a partition of S. Any event A can be represented as the union of mutually exclusive events in the following way:\n",
    "$$A = A \\cap S = A \\cap (B_1 \\cup B_2 \\cup \\dots \\cup B_n)$$$$p[A] = p[A \\cap B_1] + p[A \\cap B_2] + \\dots p[A \\cap B_n]$$$$p[A] = p[A|B_1]P[B_1] + p[A|B_2]P[B_2] + \\dots p[A|B_n]P[B_n]$$\n",
    "This can be illustrated as shown in the figure below:\n",
    "<img src=\"../images/pspace1.png\", style=\"width: 400px;\">\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Given that p = 0.8 and $\\epsilon$=0.3,\n",
    "* What would be the sum total of probabilities received? Assign this to the variable, sum_p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "tags": [
     "s1",
     "ce",
     "l1"
    ]
   },
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "e = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l2",
     "content",
     "s2"
    ]
   },
   "source": [
    "We can observe from the above that the total probability can be visualized in partitions as shown below:\n",
    "\n",
    "Suppose input was $I_0, I_1$ and the received output was $R_0, R_1$.\n",
    "\n",
    "$$p[I_0 \\cap R_0] = (1-p)(1-\\epsilon)$$\n",
    "$$p[I_0 \\cap R_1] = (1-p)\\epsilon$$\n",
    "$$p[I_1 \\cap R_0] = p\\epsilon$$\n",
    "$$p[I_1 \\cap R_1] = p(1-\\epsilon)$$\n",
    "\n",
    "<img src=\"../images/pspace3.png\", style=\"width: 600px;\">\n",
    "\n",
    "## Bayes' Rule\n",
    "\n",
    "Suppose $B_1, B_2, ..., B_n$ is a partition of a sample space, then probabiblity of event $B_j$ given that an event A has occurred is defined as:\n",
    "\n",
    "$$p[B_j|A] = \\cfrac{p[A \\cap B_j]}{p[A]} = \\cfrac{p[A|B_j]p[B_j]}{p[A]}$$\n",
    "\n",
    "$p[B_j]$ is known as a prior and $p[A|B_j]$ is known as the likelihood.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "* What is probability that 1 was received? Assign the probability to the variable p_R_1\n",
    "* What is the probability that a 0 was received? Assign the probability to the variable p_R_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l2",
     "ce",
     "s2"
    ]
   },
   "outputs": [],
   "source": [
    "#p_R_1 = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "content"
    ]
   },
   "source": [
    "The regions of 1s and 0s are illustrated in the partitions as shown in the figure:\n",
    "\n",
    "<img src=\"../images/pspace4.png\", style=\"width: 600px;\">\n",
    "\n",
    "Hence both of the probabilities add upto 1 as per the theorem of total probability.\n",
    "\n",
    "## Given receiver output was a 1, which input was more likely?\n",
    "\n",
    "Assuming that a 1 was received, let us find out which input was more likely? To formulate this problem using the bayesian theorem,\n",
    "\n",
    "Is $p(I=1|R=1)$ > $p(I=0|R=1)$?\n",
    "\n",
    "$$p(I=1|R=1) = \\cfrac{p(R=1|I=1)p(I=1)}{p(R=1)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$p(I=0|R=1) = \\cfrac{p(R=1|I=0)p(I=0)}{p(R=1)}$$\n",
    "\n",
    "\n",
    "### Exercise\n",
    "\n",
    "* Compute probability that input was 1 given that the received output was a 1 and assign it to p_i1r1.\n",
    "* Compute probability that input was a 0, given that the received output was a 1 and assign it to p_i0r1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l3",
     "s3",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "#p_i1r1 = \n",
    "#p_i0r1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l3",
     "s3",
     "hint"
    ]
   },
   "source": [
    "Use the value of p(R=1) from the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l4",
     "s4",
     "content"
    ]
   },
   "source": [
    "We see that the probability that the input was 1 is far more likely than the probability that the input was a 0, when we know that the output was a 1. This is intutitive as the probability of the input being 1 is high at probability 0.8 and the probability of the error is low at 0.3. \n",
    "\n",
    "<img src=\"../images/pspace4.png\", style=\"width: 600px;\">\n",
    "\n",
    "## Credit Approval Process\n",
    "\n",
    "The credit approval process is applied to customers whose credit history is at various levels, low-risk, mid-risk and high-risk. The task is to examine the process particularly for medium-risk and high-risk accounts.  The transaction is approved after validating an account for t seconds and the customer has still not defaulted. It is known that the mid-risk accounts have a 'credit default' rate of $\\alpha$. The high-risk accounts have a credit risk of 100$\\alpha$ as shown in the figure below:\n",
    "\n",
    "<img src=\"../images/exp-credit-risk.png\", style=\"width: 600px;\">\n",
    "\n",
    "### Exercise\n",
    "\n",
    "For this problem assume that we have pooled all mid-risk and high-risk accounts together and are randomly selecting an account from this pool.\n",
    "\n",
    "Let A be the event “transactions are still valid after t seconds,” and let M be the event “transactions are mid-risk,” and H the event “transactions are high-risk”.\n",
    "\n",
    "By the theorem on total probability we have:\n",
    "$p(A) = p(A|M)p(M) + p(A|H)p(H)$\n",
    "\n",
    "Assume the ratio of credit accounts of medium-risk and high-risk are in the ratio of 0.75:0.25.\n",
    "\n",
    "Given,\n",
    "\n",
    "p(A|M) = p_AM = $e^{-\\alpha t}$\n",
    "p(A|H) = p_AH = $e^{-100\\alpha t}$\n",
    "\n",
    "What is the probability that a randomly selected account has not defaulted after t=200 seconds? Assign this probability score to the variable p_A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l4",
     "s4",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = 200\n",
    "alpha = 5e-5\n",
    "\n",
    "p_AM = np.exp(-alpha*t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "s4",
     "l4",
     "hint"
    ]
   },
   "source": [
    "Use theorem of total probability, $p(A) = p(A|M)p(M) + p(A|H)p(H)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l5",
     "content",
     "s5"
    ]
   },
   "source": [
    "## Probability that the Approved transactions are of Medium-risk\n",
    "\n",
    "* Given that the transactions are approved after validating the transactions for t=200 seconds, what is the probability that are of medium risk?\n",
    "* Assign your answer to the variable, p_MA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l5",
     "ce",
     "s5"
    ]
   },
   "outputs": [],
   "source": [
    "# p_MA = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l5",
     "s5",
     "hint"
    ]
   },
   "source": [
    "Use Bayes rule:\n",
    "\n",
    "$$p(M|A) = \\cfrac{p(A|M)\\times p(M)}{p(A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "content",
     "l6",
     "s6"
    ]
   },
   "source": [
    "## Dependency of Testing Time on Probability of Medium Risk Approved Transactions\n",
    "\n",
    "### Exercise\n",
    "\n",
    "* Given that the transactions are approved, how long should you test a transaction given that 95% of the approved transactions are medium risk?\n",
    "\n",
    "\n",
    "Let A be the event “transaction is still valid after t seconds,” and let G be the event “chip is good,” and H be the event “chip is bad.” The problem requires that we find the value of t for which\n",
    "\n",
    "\n",
    "$$p[M|A] = 0.95$$\n",
    "\n",
    "You can determine $p[M|A]$ using Bayes Theorem:\n",
    "\n",
    "$$p[M|A] = \\cfrac{p[A|M]p[M]}{p[A|M]p[M] + p[A|H]p[H]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "ce",
     "l6",
     "s6"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.697185198\n"
     ]
    }
   ],
   "source": [
    "t = np.log(3.8)/(99*alpha)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l6",
     "s6",
     "hint"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l7",
     "s7",
     "content"
    ]
   },
   "source": [
    "### Solution\n",
    "\n",
    "$$p[M|A] = \\cfrac{p[A|M]p[M]}{p[A|M]p[M] + p[A|H]p[H]}$$\n",
    "\n",
    "$$ 0.95 = \\cfrac{e^{(-\\alpha t)} \\times 0.6}{e^{(-\\alpha t)} \\times 0.6 + 0.2 \\times e^{(-100\\alpha t)}}$$\n",
    "\n",
    "$$ 0.95 \\times 0.6 e^{(-\\alpha t)} + 0.2\\times 0.95e^{(-100\\alpha t)} = 0.6e^{(-\\alpha t)}$$\n",
    "\n",
    "$$ 0.05 \\times 0.6 e^{(-\\alpha t)} = 0.2 \\times 0.95e^{(-100\\alpha t)} $$\n",
    "\n",
    "$$ e^{99\\alpha t} = 3.8$$\n",
    "$$ t = \\cfrac{log(3.8)}{99\\alpha}$$\n",
    "\n",
    "You can now solve for t given alpha.\n",
    "\n",
    "## Increase the Testing time\n",
    "\n",
    "Increase the testing time for the transactions to t=2000 seconds to approve a transaction. How does the probability of medium risk accounts change? \n",
    "* Assign the probability values to p_MA and p_HA given $\\alpha$ = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "tags": [
     "l7",
     "s7",
     "ce"
    ]
   },
   "outputs": [],
   "source": [
    "# Write function to take in the parameters and return the probability\n",
    "\n",
    "def prob_MA(t, alpha):\n",
    "    '''\n",
    "    Given the exponential distribution t, alpha, return the probabilities, p(M|A) and p(H|A).\n",
    "    \n",
    "    Args:\n",
    "        t (float): time in seconds\n",
    "        alpha (float): exponential distribution parameter (decay parameter)\n",
    "    \n",
    "    Returns:\n",
    "        (p_MA, p_HA): A tuple of bayesian probabilities.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "l7",
     "s7",
     "hint"
    ]
   },
   "source": [
    "Call the function prob_MA(2000, 5e-5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "executed_sections": [],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
